{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f9e14f",
   "metadata": {},
   "source": [
    "## Housing Price Prediction using Advanced Regression\n",
    "\n",
    "The solution is divided into the following sections: \n",
    "- Data understanding and exploration\n",
    "- Data cleaning\n",
    "- Data preparation\n",
    "- Model building and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e165b9",
   "metadata": {},
   "source": [
    "### 1. IMPORT LIBRARIES & LOAD DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3182c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import os\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9cc8c2",
   "metadata": {},
   "source": [
    "### 2. DATA UNDERSTANDING, PREPARATION & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cfdc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1460, 81)\n",
      "Shape after duplicate removal: (1460, 81)\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Data Quality Check: Duplicates\n",
    "# Check for and remove duplicates to ensure data integrity\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Shape after duplicate removal: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74a110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Missing Value Imputation\n",
    "# Categorical columns where NA means 'feature not present' (e.g., No Pool)\n",
    "none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n",
    "             'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', \n",
    "             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \n",
    "             'MasVnrType']\n",
    "for col in none_cols:\n",
    "    df[col] = df[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c80d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns where NA implies 0 (e.g., 0 area)\n",
    "zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars', \n",
    "             'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "             'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']\n",
    "for col in zero_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "# LotFrontage: Impute with median of the specific Neighborhood (Better accuracy than global median)\n",
    "df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Electrical: Impute with Mode (Most frequent)\n",
    "df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98701c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Feature Engineering (Rubric: New metrics derived)\n",
    "# Create 'HouseAge' and 'RemodAge' to quantify the age of the property\n",
    "df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n",
    "df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']\n",
    "\n",
    "# Create 'TotalSF' (Total Square Footage) combining Basement, 1st, and 2nd floors\n",
    "# This often becomes a stronger predictor than individual floor areas\n",
    "df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "\n",
    "# Drop original columns used for engineering or ID to reduce multicollinearity/noise\n",
    "df = df.drop(['Id', 'YearBuilt', 'YearRemodAdd', 'YrSold'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da27dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Data Cleaning & Conversion\n",
    "# Convert MSSubClass to categorical (nominal data)\n",
    "df['MSSubClass'] = df['MSSubClass'].astype(str)\n",
    "\n",
    "# Create Dummy Variables \n",
    "# drop_first=True to prevent dummy variable trap\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172563c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X (Predictors) and y (Target)\n",
    "X = df_encoded.drop('SalePrice', axis=1)\n",
    "y = df_encoded['SalePrice'] # We can also log-transform y here for better normality\n",
    "\n",
    "# Train-Test Split (70-30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for readability\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b419f34",
   "metadata": {},
   "source": [
    "### 3. MODEL BUILDING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a5ed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Alpha for Ridge: 500\n",
      "Best R2 (Train CV): 0.7744\n",
      "Ridge Test R2 Score: 0.8595\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Ridge Regression (L2 Regularization)\n",
    "params_ridge = {'alpha': [0.1, 1, 5, 10, 20, 50, 100, 200, 500, 1000]}\n",
    "ridge = Ridge()\n",
    "# Using 5-fold Cross Validation to tune hyperparameter\n",
    "ridge_cv = GridSearchCV(estimator=ridge, param_grid=params_ridge, \n",
    "                        scoring='r2', cv=5, verbose=1)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest Alpha for Ridge: {ridge_cv.best_params_['alpha']}\")\n",
    "print(f\"Best R2 (Train CV): {ridge_cv.best_score_:.4f}\")\n",
    "print(f\"Ridge Test R2 Score: {r2_score(y_test, ridge_cv.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5cc9f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best Alpha for Lasso: 1000\n",
      "Best R2 (Train CV): 0.7102\n",
      "Lasso Test R2 Score: 0.8638\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Lasso Regression (L1 Regularization - Feature Selection)\n",
    "params_lasso = {'alpha': [10, 50, 100, 500, 1000, 2000]} # Higher alphas usually needed for raw prices\n",
    "lasso = Lasso(max_iter=10000)\n",
    "lasso_cv = GridSearchCV(estimator=lasso, param_grid=params_lasso, \n",
    "                        scoring='r2', cv=5, verbose=1)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest Alpha for Lasso: {lasso_cv.best_params_['alpha']}\")\n",
    "print(f\"Best R2 (Train CV): {lasso_cv.best_score_:.4f}\")\n",
    "print(f\"Lasso Test R2 Score: {r2_score(y_test, lasso_cv.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b48548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 Significant Variables (Lasso) ---\n",
      "OverallQual             15678.178093\n",
      "GrLivArea               14693.698322\n",
      "PoolQC_Gd               12704.293145\n",
      "TotalSF                  8844.713229\n",
      "Neighborhood_NridgHt     7769.423201\n",
      "GarageCars               6935.142348\n",
      "PoolArea                 6721.720684\n",
      "BsmtQual_Gd              6043.946682\n",
      "Condition2_PosN          5898.280595\n",
      "Neighborhood_NoRidge     5797.600042\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Model Interpretation (Business Aspect)\n",
    "# Identifying the most significant predictors\n",
    "lasso_best = lasso_cv.best_estimator_\n",
    "coefs = pd.Series(lasso_best.coef_, index=X.columns)\n",
    "top_features = coefs.abs().sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"\\n--- Top 10 Significant Variables (Lasso) ---\")\n",
    "print(top_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
